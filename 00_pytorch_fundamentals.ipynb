{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version:  2.2.1\n",
      "Sat Mar 23 20:56:08 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 545.29.06              Driver Version: 545.29.06    CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4060 ...    Off | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   50C    P0              18W /  80W |     18MiB /  8188MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      2099      G   /usr/lib/xorg/Xorg                            4MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from numba import jit, cuda \n",
    "  \n",
    "print(\"PyTorch version: \", torch.__version__)\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction to tensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jens7\\AppData\\Local\\Temp\\ipykernel_5280\\1429870256.py:10: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @jit(target_backend='cuda')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "without GPU: 3.8226724999994985\n",
      "with GPU: 0.28373460000057094\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# to measure exec time \n",
    "from timeit import default_timer as timer \n",
    "\n",
    "# normal function to run on cpu \n",
    "def func(a):\t\t\t\t\t\t\t\t \n",
    "\tfor i in range(10000000): \n",
    "\t\ta[i]+= 1\t\n",
    "\n",
    "# function optimized to run on gpu \n",
    "@jit(target_backend='cuda')\t\t\t\t\t\t \n",
    "def func2(a): \n",
    "\tfor i in range(10000000): \n",
    "\t\ta[i]+= 1\n",
    "if __name__==\"__main__\": \n",
    "\tn = 10000000\t\t\t\t\t\t\t\n",
    "\ta = np.ones(n, dtype = np.float64) \n",
    "\t\n",
    "\tstart = timer() \n",
    "\tfunc(a) \n",
    "\tprint(\"without GPU:\", timer()-start)\t \n",
    "\t\n",
    "\tstart = timer() \n",
    "\tfunc2(a) \n",
    "\tprint(\"with GPU:\", timer()-start) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
